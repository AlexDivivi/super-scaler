{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41875, 3600, 3)\n",
      "(40000, 3600, 3)\n",
      "(43175, 3600, 3)\n",
      "(19850, 3600, 3)\n",
      "(34300, 3600, 3)\n",
      "(32575, 3600, 3)\n",
      "(34050, 3600, 3)\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "image_chop = 25\n",
    "\n",
    "for i in range(0,7):\n",
    "    pkl_file = open(f'../data/cat{i}.pkl', 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    data = data.reshape(int(data.shape[0] * image_chop), int(data.shape[1] / image_chop), 3)\n",
    "    print(data.shape)\n",
    "    pkl_file.close()\n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(41875, 3600, 3)\n",
      "(40000, 3600, 3)\n",
      "(43175, 3600, 3)\n",
      "(19850, 3600, 3)\n",
      "(34300, 3600, 3)\n",
      "(32575, 3600, 3)\n",
      "(34050, 3600, 3)\n",
      "Sample size: 245825\n"
     ]
    }
   ],
   "source": [
    "print(len(all_data))\n",
    "samples = 0\n",
    "for i in range(0,7):\n",
    "    print(all_data[i].shape)\n",
    "    samples += all_data[i].shape[0]\n",
    "print(f'Sample size: {samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "D_in = all_data[1].shape[1]\n",
    "H1 = 2700\n",
    "H2 = 1800\n",
    "D_out = 900\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = image_chop\n",
    "epochs = 100\n",
    "\n",
    "# Regularisierung\n",
    "weight_decay=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            nn.Linear(D_in, H1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H1, H2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2, D_out)\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            nn.Linear(D_out, H2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2, H1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H1, D_in),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=3600, out_features=2700, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2700, out_features=1800, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1800, out_features=900, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=900, out_features=1800, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1800, out_features=2700, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=2700, out_features=3600, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = autoencoder()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSNR(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PSNR, self).__init__()\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        return Variable(torch.tensor(10 * math.log10((torch.max(target) * torch.max(target)) / F.mse_loss(input, target))), requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = PSNR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 PSNR: 13.427236557006836\n",
      "2 PSNR: 13.427236557006836\n",
      "4 PSNR: 13.427236557006836\n",
      "6 PSNR: 13.427236557006836\n",
      "8 PSNR: 13.427236557006836\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f0c614979151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Berechne die Vorhersage (foward step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Berechne den Fehler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-6f1efc0a8670>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "loss_hist = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    for bulk in range(len(all_data)):\n",
    "        x = torch.tensor(all_data[bulk], dtype=torch.float32, device=device)\n",
    "        for batch in range(0, int(x.shape[0]/batch_size)):\n",
    "            \n",
    "            # Berechne den Batch\n",
    "            batch_x = x[batch * batch_size : (batch + 1) * batch_size, :].transpose(1, 2)\n",
    "        \n",
    "            # Berechne die Vorhersage (foward step)\n",
    "            outputs = model.forward(batch_x)\n",
    "\n",
    "            # Berechne den Fehler\n",
    "            loss = criterion(outputs, batch_x)\n",
    "        \n",
    "            # Berechne die Gradienten und Aktualisiere die Gewichte (backward step)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    # Berechne den Fehler (Ausgabe des Fehlers alle x Iterationen)\n",
    "    if t % 2 == 0:\n",
    "        loss_hist.append(loss.item())\n",
    "        print(t, f\"PSNR: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd9401af4e0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.7/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type autoencoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.cpu(), '../data/models/ae_x2_psnr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
